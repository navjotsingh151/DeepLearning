{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendation System using Boltzmann Machine and Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dataset\n",
    "\n",
    "### 1. Movie Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0                                   1                             2\n",
      "0   1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1   2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2   3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3   4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4   5  Father of the Bride Part II (1995)                        Comedy\n",
      "5   6                         Heat (1995)         Action|Crime|Thriller\n",
      "6   7                      Sabrina (1995)                Comedy|Romance\n",
      "7   8                 Tom and Huck (1995)          Adventure|Children's\n",
      "8   9                 Sudden Death (1995)                        Action\n",
      "9  10                    GoldenEye (1995)     Action|Adventure|Thriller\n",
      "\n",
      "Shape of Movies set  (3883, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "movies = pd.read_csv('ml-1m/movies.dat',\n",
    "                     sep= '::',\n",
    "                     header = None,\n",
    "                     engine = 'python',\n",
    "                     encoding = 'latin-1'\n",
    "                     )\n",
    "print(movies.head(10))\n",
    "print(\"\\nShape of Movies set \", movies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. User Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0  1   2   3      4\n",
      "0   1  F   1  10  48067\n",
      "1   2  M  56  16  70072\n",
      "2   3  M  25  15  55117\n",
      "3   4  M  45   7  02460\n",
      "4   5  M  25  20  55455\n",
      "5   6  F  50   9  55117\n",
      "6   7  M  35   1  06810\n",
      "7   8  M  25  12  11413\n",
      "8   9  M  25  17  61614\n",
      "9  10  F  35   1  95370\n",
      "\n",
      "Shape of user set  (6040, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user = pd.read_csv('ml-1m/users.dat',\n",
    "                     sep= '::',\n",
    "                     header = None,\n",
    "                     engine = 'python',\n",
    "                     encoding = 'latin-1'\n",
    "                     )\n",
    "\n",
    "print(user.head(10))\n",
    "print(\"\\nShape of user set \", user.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Rating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0     1  2          3\n",
      "0  1  1193  5  978300760\n",
      "1  1   661  3  978302109\n",
      "2  1   914  3  978301968\n",
      "3  1  3408  4  978300275\n",
      "4  1  2355  5  978824291\n",
      "5  1  1197  3  978302268\n",
      "6  1  1287  5  978302039\n",
      "7  1  2804  5  978300719\n",
      "8  1   594  4  978302268\n",
      "9  1   919  4  978301368\n",
      "\n",
      "Shape of rating set  (1000209, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rating = pd.read_csv('ml-1m/ratings.dat',\n",
    "                     sep= '::',\n",
    "                     header = None,\n",
    "                     engine = 'python',\n",
    "                     encoding = 'latin-1'\n",
    "                     )\n",
    "\n",
    "print(rating.head(10))\n",
    "print(\"\\nShape of rating set \", rating.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Training and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Set : (79999, 4)\n"
     ]
    }
   ],
   "source": [
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter='\\t')\n",
    "\n",
    "# converting to array\n",
    "training_set = np.array(training_set, dtype = int)\n",
    "print(\"Shape of Training Set :\", training_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Test Set : (19999, 4)\n"
     ]
    }
   ],
   "source": [
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter='\\t')\n",
    "\n",
    "# converting to array\n",
    "test_set = np.array(test_set, dtype = int)\n",
    "print(\"Shape of Test Set :\", test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the number of user and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "1682\n"
     ]
    }
   ],
   "source": [
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "print(nb_users)\n",
    "\n",
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
    "print(nb_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the data into an array with users in line and movies in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[:,1][data[:,0]==id_users]\n",
    "        id_rating = data[:, 2][data[:, 0] == id_users]\n",
    "        rating = np.zeros(nb_movies)\n",
    "        rating[id_movies-1] = id_rating\n",
    "        new_data.append(list(rating))\n",
    "    return new_data\n",
    "\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the data into Torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the rating into binary rating 1 (liked) and 0 (not liked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[training_set == 0 ] = -1 # Not rated by user\n",
    "training_set[training_set == 1 ] = 0\n",
    "training_set[training_set == 2 ] = 0\n",
    "training_set[training_set >= 3 ] = 1\n",
    "\n",
    "test_set[test_set == 0 ] = -1 # Not rated by user\n",
    "test_set[test_set == 1 ] = 0\n",
    "test_set[test_set == 2 ] = 0\n",
    "test_set[test_set >= 3 ] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating architecture of the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    #nv : Number of movies\n",
    "    #nh : Number of features (user defined)\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv) # Weights matrics for Hidden and Visible Node\n",
    "        self.a = torch.randn(1, nh)  # Bias for hidden node\n",
    "        self.b = torch.randn(1, nv)  # Bias for visible node\n",
    "    \n",
    "    def sample_h(self, x):   #x is visible node\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    \n",
    "    def sample_v(self, y): #y is hidden node\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    \n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        self.b += torch.sum((v0 - vk),0)\n",
    "        self.a += torch.sum((ph0 - phk),0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1682]) torch.Size([1, 1682]) torch.Size([1, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5462,  0.7726, -0.0237,  0.2317, -2.0629, -0.6503, -1.1439,  1.3201,\n",
       "         -0.7859, -0.0381, -0.0084,  0.7152, -1.6527,  0.6482, -0.2852, -1.7392,\n",
       "          1.3449, -0.5556,  0.4475,  1.5154,  2.1418,  1.3434,  0.2634, -0.7262,\n",
       "          0.6484, -2.0660,  1.9452, -1.0321, -0.1082, -1.2566, -0.9497,  0.5279,\n",
       "         -0.8019,  0.1546, -0.2203,  0.0570, -0.6431,  0.1618, -1.4387,  0.2779,\n",
       "          0.1663, -0.1109, -0.5057,  1.5321, -0.6253,  0.7436, -0.7225,  1.8034,\n",
       "          0.4667, -0.1762, -1.0167, -0.8764,  1.1631,  0.4188, -0.3199,  0.1428,\n",
       "          0.1303, -1.3454,  0.2416, -0.9323,  0.6393, -1.1094, -1.7462, -0.1782,\n",
       "         -0.5228,  0.1020, -0.6122, -1.2958,  1.1010,  0.6858,  0.1612,  2.1209,\n",
       "         -0.5224,  1.0597,  0.7066,  0.0809,  0.1546, -0.8807, -1.4025,  1.2550,\n",
       "         -1.1381, -0.1660,  1.4488,  1.6292, -0.3027, -0.9113,  0.4493, -0.0310,\n",
       "          0.6262, -0.6491,  0.0594,  2.9500, -0.4485,  1.2207,  1.6224,  0.4517,\n",
       "         -0.0432, -0.1452, -0.8168, -0.7009]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv = len(training_set[0])\n",
    "nh = 100\n",
    "batch_size = 100\n",
    "\n",
    "rbm = RBM(nv, nh)\n",
    "print(rbm.W.shape, rbm.b.shape, rbm.a.shape)\n",
    "rbm.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 0.24706202745437622\n",
      "epoch: 2 loss: 0.24485741555690765\n",
      "epoch: 3 loss: 0.2502173185348511\n",
      "epoch: 4 loss: 0.24426428973674774\n",
      "epoch: 5 loss: 0.249492347240448\n",
      "epoch: 6 loss: 0.24944064021110535\n",
      "epoch: 7 loss: 0.24622675776481628\n",
      "epoch: 8 loss: 0.2487250119447708\n",
      "epoch: 9 loss: 0.24725304543972015\n",
      "epoch: 10 loss: 0.24780556559562683\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "for epoch in range(1, nb_epoch+1):\n",
    "    train_loss = 0 \n",
    "    s = 0. # counter\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = training_set[id_user : id_user + batch_size]\n",
    "        v0 = training_set[id_user : id_user + batch_size]\n",
    "        ph0,_ = rbm.sample_h(v0)\n",
    "        for k in range(15):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            vk[v0<0] = v0[v0<0]\n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
    "        s += 1.\n",
    "    print(f'epoch: {epoch} loss: {train_loss/s}')\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2414473593235016\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0 \n",
    "s = 0. # counter\n",
    "for id_user in range(0, nb_users):\n",
    "    v = training_set[id_user : id_user + 1]\n",
    "    vt = test_set[id_user : id_user + 1]\n",
    "    if len(vt[vt>=0]) > 0  :\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "        s += 1.\n",
    "print(f'loss: {test_loss/s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
